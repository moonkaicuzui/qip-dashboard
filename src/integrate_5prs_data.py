#!/usr/bin/env python3
"""
5PRS ë°ì´í„° í†µí•© ìŠ¤í¬ë¦½íŠ¸
Google Driveì™€ ë¡œì»¬ í´ë”ì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ ê¸°ì¡´ 5PRS Dashboardì™€ í†µí•©
"""

import os
import sys
import json
import pandas as pd
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional
import argparse
import numpy as np

# Add parent directory for imports
sys.path.append(str(Path(__file__).parent.parent))

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Import Google Drive Manager
try:
    from src.google_drive_manager import GoogleDriveManager
    GOOGLE_DRIVE_AVAILABLE = True
except ImportError:
    logger.warning("Google Drive Manager not available")
    GOOGLE_DRIVE_AVAILABLE = False


class DataIntegrator:
    """5PRS ë°ì´í„° í†µí•© í´ë˜ìŠ¤"""
    
    def __init__(self, month: str, year: int, use_google_drive: bool = True):
        self.month = month
        self.year = year
        self.month_num = self.get_month_number(month)
        self.input_dir = Path('input_files')
        self.output_dir = Path('output_files/dashboards/5prs/data')
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.use_google_drive = use_google_drive and GOOGLE_DRIVE_AVAILABLE
        self.drive_manager = None
        
        # Initialize Google Drive if enabled
        if self.use_google_drive:
            try:
                self.drive_manager = GoogleDriveManager()
                if not self.drive_manager.initialize():
                    logger.warning("Google Drive initialization failed, falling back to local files")
                    self.use_google_drive = False
            except Exception as e:
                logger.warning(f"Google Drive setup failed: {e}, using local files only")
                self.use_google_drive = False
        
    def get_month_number(self, month: str) -> int:
        """ì›” ì´ë¦„ì„ ìˆ«ìë¡œ ë³€í™˜"""
        months = {
            'january': 1, 'february': 2, 'march': 3, 'april': 4,
            'may': 5, 'june': 6, 'july': 7, 'august': 8,
            'september': 9, 'october': 10, 'november': 11, 'december': 12
        }
        return months.get(month.lower(), 0)
    
    def find_data_files(self) -> List[Path]:
        """Google Driveì™€ ë¡œì»¬ í´ë”ì—ì„œ ë°ì´í„° íŒŒì¼ ì°¾ê¸°"""
        files = []
        
        # 1. Google Driveì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        if self.use_google_drive and self.drive_manager:
            google_file = self._download_from_google_drive()
            if google_file and google_file.exists():
                files.append(google_file)
                logger.info(f"âœ… Google Driveì—ì„œ ë°ì´í„° ë¡œë“œ: {google_file.name}")
        
        # 2. ë¡œì»¬ í´ë”ì—ì„œ ë°ì´í„° ì°¾ê¸°
        local_files = self._find_local_files()
        files.extend(local_files)
        
        # ì¤‘ë³µ ì œê±°
        files = list(set(files))
        
        logger.info(f"ì´ ì°¾ì€ ë°ì´í„° íŒŒì¼: {len(files)}ê°œ")
        for f in files:
            logger.info(f"  - {f.name}")
        
        return files
    
    def _download_from_google_drive(self) -> Optional[Path]:
        """Google Driveì—ì„œ 5PRS ë°ì´í„° ë‹¤ìš´ë¡œë“œ"""
        try:
            # Google Drive ê²½ë¡œ ì„¤ì •
            drive_path = f"monthly_data/{self.year}_{self.month_num:02d}/5prs_data.csv"
            local_path = Path(f".cache/5prs_data_{self.month}_{self.year}.csv")
            local_path.parent.mkdir(parents=True, exist_ok=True)
            
            # ë‹¤ìš´ë¡œë“œ ì‹¤í–‰
            if self.drive_manager.download_specific_file(drive_path, str(local_path)):
                return local_path
            else:
                logger.warning(f"Google Driveì—ì„œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {drive_path}")
                return None
                
        except Exception as e:
            logger.error(f"Google Drive ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def _find_local_files(self) -> List[Path]:
        """ë¡œì»¬ í´ë”ì—ì„œ 5PRS ë°ì´í„° íŒŒì¼ ì°¾ê¸°"""
        files = []
        
        # ì§€ì›í•˜ëŠ” í™•ì¥ì
        extensions = ['.csv', '.xlsx', '.xls', '.json']
        
        # ê²€ìƒ‰í•  ë””ë ‰í† ë¦¬ë“¤
        search_dirs = [
            self.input_dir,
            self.input_dir / '5prs',
            self.input_dir / '5PRS',
            Path('output_files/dashboards/5prs/data')
        ]
        
        # íŒŒì¼ íŒ¨í„´ ì •ì˜
        if self.month.lower() == 'all':
            patterns = ["*5prs*", "*PRS*", "*qip_trainer*"]
        else:
            patterns = [
                f"*5prs*{self.month}*",
                f"*5prs*{self.year}_{self.month_num:02d}*",
                f"*{self.month}*5prs*",
                f"5prs_data_{self.month}.csv"
            ]
        
        # ê° ë””ë ‰í† ë¦¬ì—ì„œ íŒŒì¼ ê²€ìƒ‰
        for search_dir in search_dirs:
            if search_dir.exists():
                for pattern in patterns:
                    for ext in extensions:
                        found = list(search_dir.glob(f"{pattern}{ext}"))
                        files.extend(found)
                        # ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´ ê²€ìƒ‰
                        found = list(search_dir.glob(f"{pattern.upper()}{ext}"))
                        files.extend(found)
        
        return list(set(files))  # ì¤‘ë³µ ì œê±°
    
    def read_file(self, file_path: Path) -> Optional[pd.DataFrame]:
        """íŒŒì¼ ì½ê¸° (CSV, Excel, JSON ì§€ì›)"""
        try:
            ext = file_path.suffix.lower()
            
            if ext == '.csv':
                # Use on_bad_lines='skip' for pandas >= 1.3.0
                try:
                    df = pd.read_csv(file_path, encoding='utf-8', on_bad_lines='skip')
                except TypeError:
                    # Fallback for older pandas versions
                    df = pd.read_csv(file_path, encoding='utf-8')
            elif ext in ['.xlsx', '.xls']:
                df = pd.read_excel(file_path)
            elif ext == '.json':
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    if isinstance(data, dict) and 'rawData' in data:
                        df = pd.DataFrame(data['rawData'])
                    else:
                        df = pd.DataFrame(data)
            else:
                logger.warning(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {ext}")
                return None
            
            logger.info(f"âœ… íŒŒì¼ ì½ê¸° ì„±ê³µ: {file_path.name} ({len(df)} rows)")
            return df
            
        except Exception as e:
            logger.error(f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ {file_path.name}: {e}")
            return None
    
    def standardize_columns(self, df: pd.DataFrame) -> pd.DataFrame:
        """ì»¬ëŸ¼ëª… í‘œì¤€í™”"""
        column_mapping = {
            # ë‚ ì§œ
            'date': 'date',
            'Date': 'date',
            'inspection date': 'date',
            'Inspection Date': 'date',
            
            # ê²€ì‚¬ì›
            'inspector id': 'inspector_id',
            'Inspector ID': 'inspector_id',
            'inspector': 'inspector_id',
            'checker': 'inspector_id',
            
            # TQC
            'tqc id': 'tqc_id',
            'TQC ID': 'tqc_id',
            'tqc': 'tqc_id',
            'TQC': 'tqc_id',
            
            # ê±´ë¬¼/ë¼ì¸
            'building': 'building',
            'Building': 'building',
            'area': 'building',
            'AREA': 'building',
            'line': 'line',
            'Line': 'line',
            
            # ì œí’ˆ
            'product': 'product',
            'Product': 'product',
            'pcs': 'product',
            'item': 'product',
            
            # ìˆ˜ëŸ‰
            'validation qty': 'validation_qty',
            'Validation Qty': 'validation_qty',
            'Valiation Qty': 'validation_qty',  # ì˜¤íƒ€ ì²˜ë¦¬
            'validated qty': 'validation_qty',
            'pass qty': 'pass_qty',
            'Pass Qty': 'pass_qty',
            'pass': 'pass_qty',
            'passed': 'pass_qty',
            'reject qty': 'reject_qty',
            'Reject Qty': 'reject_qty',
            'reject': 'reject_qty',
            'failed': 'reject_qty',
            
            # ê²°ê³¼
            'result': 'result',
            'Result': 'result',
            '5PRS_PASS': 'result',
            
            # ë¶ˆëŸ‰ ìœ í˜•
            'defect type': 'defect_type',
            'Defect Type': 'defect_type',
            'defects': 'defect_type'
        }
        
        # ì»¬ëŸ¼ëª… ë³€ê²½
        df = df.rename(columns=column_mapping)
        
        # í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì¶”ê°€
        if 'date' not in df.columns:
            df['date'] = f"{self.month_num}/1/{self.year}"
        
        if 'inspector_id' not in df.columns and 'tqc_id' in df.columns:
            df['inspector_id'] = df['tqc_id']
        
        if 'building' not in df.columns:
            df['building'] = '5PRS'
        
        if 'line' not in df.columns:
            df['line'] = 'Line 1'
        
        if 'pass_qty' not in df.columns and 'result' in df.columns:
            df['pass_qty'] = df['result'].apply(lambda x: 100 if str(x).lower() == 'pass' else 0)
            df['reject_qty'] = df['result'].apply(lambda x: 0 if str(x).lower() == 'pass' else 10)
        
        return df
    
    def integrate_data(self, dataframes: List[pd.DataFrame]) -> pd.DataFrame:
        """ì—¬ëŸ¬ ë°ì´í„°í”„ë ˆì„ í†µí•©"""
        if not dataframes:
            logger.warning("í†µí•©í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return pd.DataFrame()
        
        # ëª¨ë“  ë°ì´í„°í”„ë ˆì„ í•©ì¹˜ê¸°
        integrated = pd.concat(dataframes, ignore_index=True)
        
        # ì¤‘ë³µ ì œê±° (ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ë§Œ ì‚¬ìš©)
        dedup_cols = []
        if 'date' in integrated.columns:
            dedup_cols.append('date')
        if 'inspector_id' in integrated.columns:
            dedup_cols.append('inspector_id')
        if 'product' in integrated.columns:
            dedup_cols.append('product')
        elif 'Model' in integrated.columns:
            dedup_cols.append('Model')
            
        if dedup_cols:
            integrated = integrated.drop_duplicates(subset=dedup_cols, keep='first')
        
        logger.info(f"âœ… ë°ì´í„° í†µí•© ì™„ë£Œ: {len(integrated)} rows")
        return integrated
    
    def calculate_statistics(self, df: pd.DataFrame) -> Dict[str, Any]:
        """í†µê³„ ê³„ì‚°"""
        stats = {
            'total_records': len(df),
            'unique_inspectors': df['inspector_id'].nunique() if 'inspector_id' in df else 0,
            'unique_tqcs': df['tqc_id'].nunique() if 'tqc_id' in df else 0,
            'unique_buildings': df['building'].nunique() if 'building' in df else 0,
            'total_pass': 0,
            'total_reject': 0,
            'pass_rate': 0,
            'date_range': None
        }
        
        # Pass/Reject ê³„ì‚°
        if 'pass_qty' in df and 'reject_qty' in df:
            stats['total_pass'] = int(df['pass_qty'].sum())
            stats['total_reject'] = int(df['reject_qty'].sum())
            total = stats['total_pass'] + stats['total_reject']
            if total > 0:
                stats['pass_rate'] = round((stats['total_pass'] / total) * 100, 2)
        
        # ë‚ ì§œ ë²”ìœ„
        if 'date' in df:
            try:
                df['date_parsed'] = pd.to_datetime(df['date'], errors='coerce')
                valid_dates = df['date_parsed'].dropna()
                if not valid_dates.empty:
                    stats['date_range'] = {
                        'start': valid_dates.min().strftime('%Y-%m-%d'),
                        'end': valid_dates.max().strftime('%Y-%m-%d')
                    }
            except:
                pass
        
        return stats
    
    def generate_chart_data(self, df: pd.DataFrame) -> Dict[str, Any]:
        """ì°¨íŠ¸ìš© ë°ì´í„° ìƒì„±"""
        charts = {}
        
        # ì¼ë³„ ì¶”ì´ ì°¨íŠ¸
        if 'date' in df and 'pass_qty' in df and 'reject_qty' in df:
            try:
                df['date_parsed'] = pd.to_datetime(df['date'], errors='coerce')
                daily = df.groupby('date_parsed').agg({
                    'pass_qty': 'sum',
                    'reject_qty': 'sum'
                }).reset_index()
                
                daily['pass_rate'] = (daily['pass_qty'] / (daily['pass_qty'] + daily['reject_qty']) * 100).round(2)
                
                charts['daily_trend'] = {
                    'labels': [d.strftime('%m/%d') if pd.notna(d) else '' for d in daily['date_parsed']],
                    'pass_rates': daily['pass_rate'].tolist(),
                    'pass_qty': daily['pass_qty'].tolist(),
                    'reject_qty': daily['reject_qty'].tolist()
                }
            except:
                pass
        
        # ê±´ë¬¼ë³„ ì„±ê³¼
        if 'building' in df and 'pass_qty' in df and 'reject_qty' in df:
            building_stats = df.groupby('building').agg({
                'pass_qty': 'sum',
                'reject_qty': 'sum'
            }).reset_index()
            
            building_stats['total'] = building_stats['pass_qty'] + building_stats['reject_qty']
            building_stats['pass_rate'] = (building_stats['pass_qty'] / building_stats['total'] * 100).round(2)
            
            charts['building_performance'] = {
                'labels': building_stats['building'].tolist(),
                'pass_rates': building_stats['pass_rate'].tolist(),
                'totals': building_stats['total'].tolist()
            }
        
        # Top 10 ê²€ì‚¬ì›
        if 'inspector_id' in df and 'pass_qty' in df and 'reject_qty' in df:
            inspector_stats = df.groupby('inspector_id').agg({
                'pass_qty': 'sum',
                'reject_qty': 'sum'
            }).reset_index()
            
            inspector_stats['total'] = inspector_stats['pass_qty'] + inspector_stats['reject_qty']
            inspector_stats['pass_rate'] = (inspector_stats['pass_qty'] / inspector_stats['total'] * 100).round(2)
            inspector_stats = inspector_stats.nlargest(10, 'total')
            
            charts['top_inspectors'] = {
                'labels': inspector_stats['inspector_id'].tolist(),
                'pass_rates': inspector_stats['pass_rate'].tolist(),
                'totals': inspector_stats['total'].tolist()
            }
        
        return charts
    
    def save_integrated_data(self, df: pd.DataFrame, stats: Dict, charts: Dict) -> str:
        """í†µí•© ë°ì´í„°ë¥¼ JSONìœ¼ë¡œ ì €ì¥"""
        
        # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        if self.month.lower() == 'all':
            output_file = self.output_dir / f"integrated_5prs_{self.year}_all.json"
        else:
            output_file = self.output_dir / f"integrated_5prs_{self.year}_{self.month_num:02d}.json"
        
        # NaN ë° Infinity ì²˜ë¦¬
        def clean_value(v):
            if isinstance(v, float):
                if np.isnan(v) or np.isinf(v):
                    return None
            return v
        
        # DataFrameì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (NaN ì²˜ë¦¬)
        records = []
        for _, row in df.iterrows():
            record = {}
            for col, val in row.items():
                record[col] = clean_value(val)
            records.append(record)
        
        # ìµœì¢… ë°ì´í„° êµ¬ì¡°
        output_data = {
            'metadata': {
                'month': self.month,
                'year': self.year,
                'generated_at': datetime.now().isoformat(),
                'version': '2.0'
            },
            'statistics': stats,
            'charts': charts,
            'raw_data': records[:1000],  # ëŒ€ì‹œë³´ë“œìš©ìœ¼ë¡œ ìµœëŒ€ 1000ê°œë§Œ
            'full_data_count': len(records)
        }
        
        # JSON ì €ì¥
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, indent=2, ensure_ascii=False, default=str)
        
        logger.info(f"âœ… í†µí•© ë°ì´í„° ì €ì¥: {output_file}")
        return str(output_file)
    
    def run(self) -> bool:
        """í†µí•© í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        logger.info(f"ğŸ“Š {self.year}ë…„ {self.month} ë°ì´í„° í†µí•© ì‹œì‘")
        
        # 1. ë°ì´í„° íŒŒì¼ ì°¾ê¸°
        files = self.find_data_files()
        if not files:
            logger.warning("ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            # ë¹ˆ ë°ì´í„°ë¡œ íŒŒì¼ ìƒì„±
            self.save_integrated_data(pd.DataFrame(), {}, {})
            return False
        
        # 2. íŒŒì¼ ì½ê¸° ë° í‘œì¤€í™”
        dataframes = []
        for file_path in files:
            df = self.read_file(file_path)
            if df is not None and not df.empty:
                df = self.standardize_columns(df)
                dataframes.append(df)
        
        if not dataframes:
            logger.warning("ì½ì„ ìˆ˜ ìˆëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            self.save_integrated_data(pd.DataFrame(), {}, {})
            return False
        
        # 3. ë°ì´í„° í†µí•©
        integrated_df = self.integrate_data(dataframes)
        
        # 4. í†µê³„ ê³„ì‚°
        stats = self.calculate_statistics(integrated_df)
        
        # 5. ì°¨íŠ¸ ë°ì´í„° ìƒì„±
        charts = self.generate_chart_data(integrated_df)
        
        # 6. ì €ì¥
        output_path = self.save_integrated_data(integrated_df, stats, charts)
        
        # 7. ìš”ì•½ ì¶œë ¥
        logger.info("=" * 50)
        logger.info(f"ğŸ“Š í†µí•© ì™„ë£Œ ìš”ì•½")
        logger.info(f"  - ì´ ë ˆì½”ë“œ: {stats['total_records']:,}")
        logger.info(f"  - ê²€ì‚¬ì› ìˆ˜: {stats['unique_inspectors']}")
        logger.info(f"  - í•©ê²©ë¥ : {stats['pass_rate']}%")
        logger.info(f"  - ì¶œë ¥ íŒŒì¼: {output_path}")
        logger.info("=" * 50)
        
        return True


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='5PRS ë°ì´í„° í†µí•© (Google Drive + ë¡œì»¬)')
    parser.add_argument('--month', type=str, required=True, help='ì›” (ì˜ˆ: august)')
    parser.add_argument('--year', type=int, default=2025, help='ë…„ë„')
    parser.add_argument('--no-google', action='store_true', help='Google Drive ì‚¬ìš© ì•ˆí•¨')
    parser.add_argument('--api-mode', action='store_true', help='API ëª¨ë“œë¡œ ì‹¤í–‰ (JSON ì¶œë ¥)')
    
    args = parser.parse_args()
    
    # í†µí•© ì‹¤í–‰
    use_google = not args.no_google
    integrator = DataIntegrator(args.month, args.year, use_google_drive=use_google)
    
    if args.api_mode:
        # API ëª¨ë“œ: JSON í˜•ì‹ìœ¼ë¡œ ë°ì´í„° ë°˜í™˜
        success = integrator.run()
        if success:
            # ìƒì„±ëœ JSON íŒŒì¼ ê²½ë¡œ ì¶œë ¥
            output_file = integrator.output_dir / f"integrated_5prs_{args.year}_{integrator.month_num:02d}.json"
            print(json.dumps({"status": "success", "file": str(output_file)}))
        else:
            print(json.dumps({"status": "error", "message": "Data integration failed"}))
    else:
        # ì¼ë°˜ ëª¨ë“œ
        success = integrator.run()
    
    sys.exit(0 if success else 1)


if __name__ == '__main__':
    main()