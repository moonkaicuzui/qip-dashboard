"""
Comprehensive Data Error Detection System
ë°ì´í„° í’ˆì§ˆ ì¢…í•© ê²€ì¦ ì‹œìŠ¤í…œ
"""

import pandas as pd
import numpy as np
import json
from datetime import datetime
import os

class DataErrorDetector:
    """í¬ê´„ì  ë°ì´í„° ì˜¤ë¥˜ ê°ì§€ í´ë˜ìŠ¤"""

    def __init__(self, year, month, latest_data_date=None):
        self.year = year
        self.month = month
        self.month_start = pd.Timestamp(year, month, 1)
        self.month_end = pd.Timestamp(year, month, 1) + pd.DateOffset(months=1) - pd.Timedelta(days=1)
        self.latest_data_date = latest_data_date  # ì‹¤ì œ ë°ì´í„° ìµœì‹  ë‚ ì§œ
        self.errors = {
            'temporal_errors': [],
            'type_errors': [],
            'position_errors': [],
            'team_errors': [],
            'attendance_errors': [],
            'duplicate_errors': [],
            'summary': {
                'total_errors': 0,
                'critical': 0,
                'warning': 0,
                'info': 0
            }
        }
        
    def detect_all_errors(self, df):
        """ëª¨ë“  ì˜¤ë¥˜ ìœ í˜• ê°ì§€"""
        print("\nğŸ” Starting Comprehensive Error Detection...")
        
        # 1. Temporal Errors
        self.detect_temporal_errors(df)
        
        # 2. TYPE Errors
        self.detect_type_errors(df)
        
        # 3. Position Errors
        self.detect_position_errors(df)
        
        # 4. Team Errors
        self.detect_team_errors(df)
        
        # 5. Attendance Errors
        self.detect_attendance_errors(df)
        
        # 6. Duplicate Errors
        self.detect_duplicate_errors(df)
        
        # Summary
        self.calculate_summary()
        
        return self.errors
    
    def add_error(self, category, error_data):
        """ì˜¤ë¥˜ ì¶”ê°€ í—¬í¼ í•¨ìˆ˜"""
        self.errors[category].append(error_data)
        
        # Update summary
        severity = error_data.get('severity', 'info')
        if severity == 'critical':
            self.errors['summary']['critical'] += 1
        elif severity == 'warning':
            self.errors['summary']['warning'] += 1
        else:
            self.errors['summary']['info'] += 1
            
    def detect_temporal_errors(self, df):
        """ì‹œê°„ ê´€ë ¨ ì˜¤ë¥˜ ê°ì§€"""
        print("  ğŸ“… Detecting temporal errors...")

        # ë¯¸ë˜ ì…ì‚¬ì ê²€ì‚¬ - ì‹¤ì œ ë°ì´í„° ê¸°ì¤€ì¼ ì´í›„ ì…ì‚¬ìëŠ” ë‚ ì§œ ì…ë ¥ ì˜¤ë¥˜ë¡œ íŒë‹¨
        from datetime import datetime
        from calendar import monthrange

        # ë°ì´í„° ìµœì‹ ì¼ ê³„ì‚° - ì‹¤ì œ ë°ì´í„° ë‚ ì§œ ì‚¬ìš© (í•˜ë“œì½”ë”© ì œê±°)
        if self.latest_data_date:
            # ì‹¤ì œ ë°ì´í„° ìµœì‹  ë‚ ì§œê°€ ì œê³µëœ ê²½ìš°
            data_latest_date = self.latest_data_date
        else:
            # ì œê³µë˜ì§€ ì•Šì€ ê²½ìš° ì›”ë§ ì‚¬ìš© (í´ë°±)
            last_day = monthrange(self.year, self.month)[1]
            data_latest_date = pd.Timestamp(self.year, self.month, last_day)

        if 'Entrance Date' in df.columns:
            # ë¯¸ë˜ ì…ì‚¬ì ê°ì§€ (ë°ì´í„° ê¸°ì¤€ì¼ ì´í›„ ì…ì‚¬)
            future_employees = df[
                (df['Entrance Date'].notna()) &
                (df['Entrance Date'] > data_latest_date)
            ]
            for _, row in future_employees.iterrows():
                entrance_date = row['Entrance Date']
                self.add_error('temporal_errors', {
                    'id': row.get('Employee No', row.get('ID No', 'N/A')),
                    'name': row.get('Full Name', row.get('Name', 'N/A')),
                    'error_type': 'ë‚ ì§œ í˜•íƒœ ì˜¤ë¥˜',
                    'error_column': 'Entrance Date',
                    'error_value': str(entrance_date)[:10] if pd.notna(entrance_date) else 'N/A',
                    'expected_value': f'{data_latest_date.strftime("%Y-%m-%d")} ì´ì „',
                    'severity': 'critical',
                    'description': f'ì…ì‚¬ì¼ì´ ë°ì´í„° ê¸°ì¤€ì¼({data_latest_date.strftime("%Y-%m-%d")}) ì´í›„',
                    'suggested_action': f'ë‚ ì§œ í˜•ì‹ í™•ì¸ ë° ìˆ˜ì • (ì •í™•í•œ í˜•ì‹: YYYY-MM-DD, ì˜ˆ: {data_latest_date.strftime("%Y-%m-%d")})'
                })
        
        if 'Stop working Date' in df.columns and 'Entrance Date' in df.columns:
            # Stop date before entrance date
            invalid_stop = df[
                (df['Stop working Date'].notna()) & 
                (df['Entrance Date'].notna()) &
                (df['Stop working Date'] < df['Entrance Date'])
            ]
            for _, row in invalid_stop.iterrows():
                self.add_error('temporal_errors', {
                    'id': row.get('Employee No', row.get('ID No', 'N/A')),
                    'name': row.get('Full Name', row.get('Name', 'N/A')),
                    'error_type': 'Invalid Date Sequence',
                    'error_column': 'Stop working Date',
                    'error_value': f"Stop: {row['Stop working Date']}, Enter: {row['Entrance Date']}",
                    'expected_value': 'Stop Date >= Entrance Date',
                    'severity': 'critical',
                    'description': 'Employee left before joining',
                    'suggested_action': 'Correct date sequence',
                    'is_resigned': True  # í‡´ì‚¬ì í‘œì‹ì„ ìœ„í•œ í”Œë˜ê·¸
                })
                
    def detect_type_errors(self, df):
        """TYPE ë¶„ë¥˜ ì˜¤ë¥˜ ê°ì§€"""
        print("  ğŸ·ï¸ Detecting TYPE classification errors...")
        
        type_column = 'ROLE TYPE STD' if 'ROLE TYPE STD' in df.columns else 'TYPE'
        
        if type_column in df.columns:
            # Missing TYPE
            missing_type = df[df[type_column].isna() | (df[type_column] == '')]
            for _, row in missing_type.iterrows():
                self.add_error('type_errors', {
                    'id': row.get('Employee No', row.get('ID No', 'N/A')),
                    'name': row.get('Full Name', row.get('Name', 'N/A')),
                    'error_type': 'Missing TYPE',
                    'error_column': type_column,
                    'error_value': 'NULL/Empty',
                    'expected_value': 'TYPE-1, TYPE-2, or TYPE-3',
                    'severity': 'critical',
                    'description': 'TYPE classification is missing',
                    'suggested_action': 'Assign appropriate TYPE'
                })
            
            # Invalid TYPE values
            valid_types = ['TYPE-1', 'TYPE-2', 'TYPE-3']
            invalid_type = df[
                df[type_column].notna() & 
                ~df[type_column].isin(valid_types)
            ]
            for _, row in invalid_type.iterrows():
                self.add_error('type_errors', {
                    'id': row.get('Employee No', row.get('ID No', 'N/A')),
                    'name': row.get('Full Name', row.get('Name', 'N/A')),
                    'error_type': 'Invalid TYPE',
                    'error_column': type_column,
                    'error_value': row[type_column],
                    'expected_value': 'TYPE-1, TYPE-2, or TYPE-3',
                    'severity': 'critical',
                    'description': f'Invalid TYPE value: {row[type_column]}',
                    'suggested_action': 'Correct to valid TYPE'
                })
            
            # TYPE Mismatch with position mapping
            self.detect_type_position_mismatch(df, type_column)
                
    def detect_type_position_mismatch(self, df, type_column):
        """ì§ê¸‰ê³¼ TYPE ë§¤í•‘ ë¶ˆì¼ì¹˜ ê°ì§€"""
        print("    ğŸ” Checking TYPE-Position mapping consistency...")
        
        # Load team structure mapping
        team_structure_path = 'HR info/team_structure_updated.json'
        position_matrix_path = 'config_files/position_condition_matrix.json'
        
        if os.path.exists(team_structure_path):
            with open(team_structure_path, 'r', encoding='utf-8') as f:
                team_structure = json.load(f)
                
            # Create mapping dictionary from team_structure
            position_to_type = {}
            for entry in team_structure.get('positions', []):
                key = (
                    entry.get('position_1st', ''),
                    entry.get('position_2nd', ''),
                    entry.get('position_3rd', ''),
                    entry.get('final_code', '')
                )
                expected_type = entry.get('role_type', '')
                if expected_type:
                    position_to_type[key] = expected_type
                    
            # Also load from position_condition_matrix if exists
            if os.path.exists(position_matrix_path):
                with open(position_matrix_path, 'r', encoding='utf-8') as f:
                    position_matrix = json.load(f)
                    
                # Build mapping from position matrix patterns
                for type_key, type_data in position_matrix.get('position_matrix', {}).items():
                    if isinstance(type_data, dict):
                        for position_key, position_data in type_data.items():
                            if position_key != 'default' and isinstance(position_data, dict):
                                patterns = position_data.get('patterns', [])
                                for pattern in patterns:
                                    # Map specific position patterns to TYPE
                                    if pattern == 'GROUP LEADER':
                                        # GROUP LEADER is TYPE-1 in TYPE-1 section, TYPE-2 in TYPE-2 section
                                        # Need to check context
                                        pass
            
            # Check each employee's TYPE against expected mapping
            for _, row in df.iterrows():
                actual_type = row.get(type_column, '')
                
                # Try to match using different column combinations
                position_1st = row.get('Position 1st', row.get('position_1st', ''))
                position_2nd = row.get('Position 2nd', row.get('position_2nd', ''))
                position_3rd = row.get('Position 3rd', row.get('position_3rd', ''))
                final_code = row.get('Final Code', row.get('final_code', ''))
                
                # Also check Position column which might contain the role
                position = row.get('Position', row.get('ì§ê¸‰', ''))
                
                # Create lookup key
                lookup_key = (position_1st, position_2nd, position_3rd, final_code)
                
                # Check if we have an expected TYPE for this position combination
                expected_type = None
                
                # First try exact match with team_structure
                if lookup_key in position_to_type:
                    expected_type = position_to_type[lookup_key]
                
                # Special case handling based on user's example
                # GROUP LEADER with final_code Q should be TYPE-2
                if position_1st == 'GROUP LEADER' and final_code == 'Q':
                    expected_type = 'TYPE-2'
                elif position and 'GROUP LEADER' in position.upper() and final_code == 'Q':
                    expected_type = 'TYPE-2'
                    
                # Check position_matrix patterns for more general rules
                if not expected_type and position:
                    position_upper = position.upper()
                    
                    # TYPE-1 positions
                    type1_positions = ['MANAGER', 'A.MANAGER', 'ASSISTANT MANAGER', '(V) SUPERVISOR', 
                                      'V.SUPERVISOR', 'V SUPERVISOR', 'AQL INSPECTOR', 'CFA CERTIFIED',
                                      'ASSEMBLY INSPECTOR', 'AUDIT & TRAINING', 'MODEL MASTER', 'SAMPLE']
                    
                    # TYPE-2 positions 
                    type2_positions = ['BOTTOM INSPECTOR', 'CUTTING INSPECTOR', 'MTL INSPECTOR', 
                                      'MATERIAL INSPECTOR', 'OCPT STFF', 'OCPT STAFF', 'OSC INSPECTOR',
                                      'QA TEAM', 'QUALITY ASSURANCE', 'RQC', 'RANDOM QUALITY CHECK',
                                      'STITCHING INSPECTOR']
                    
                    # TYPE-3 positions
                    type3_positions = ['NEW QIP MEMBER', 'NEW MEMBER', 'ì‹ ì…']
                    
                    for pos in type1_positions:
                        if pos in position_upper:
                            expected_type = 'TYPE-1'
                            break
                    
                    if not expected_type:
                        for pos in type2_positions:
                            if pos in position_upper:
                                expected_type = 'TYPE-2'
                                break
                    
                    if not expected_type:
                        for pos in type3_positions:
                            if pos in position_upper:
                                expected_type = 'TYPE-3'
                                break
                
                # If we found expected TYPE and it doesn't match actual
                if expected_type and actual_type and expected_type != actual_type:
                    position_info = f'{position_1st} / {position_2nd} / {position_3rd} / Code: {final_code}' if position_1st else position
                    self.add_error('type_errors', {
                        'id': row.get('Employee No', row.get('ID No', 'N/A')),
                        'name': row.get('Full Name', row.get('Name', 'N/A')),
                        'error_type': 'TYPE ë§¤í•‘ ë¶ˆì¼ì¹˜',
                        'error_column': type_column,
                        'error_value': actual_type,
                        'expected_value': expected_type,
                        'severity': 'critical',
                        'description': f'ì§ê¸‰ ë§¤í•‘ìƒ {expected_type}ì´ì–´ì•¼ í•˜ë‚˜ {actual_type}ë¡œ ë“±ë¡ë¨',
                        'position_info': position_info,
                        'suggested_action': f'{actual_type}ì—ì„œ {expected_type}ë¡œ ë³€ê²½ í•„ìš”'
                    })
                
    def detect_position_errors(self, df):
        """ì§ê¸‰ ê´€ë ¨ ì˜¤ë¥˜ ê°ì§€"""
        print("  ğŸ‘” Detecting position errors...")
        
        # Load position matrix if exists
        position_matrix_path = 'config_files/position_condition_matrix.json'
        if os.path.exists(position_matrix_path):
            with open(position_matrix_path, 'r', encoding='utf-8') as f:
                position_matrix = json.load(f)
                valid_positions = position_matrix.get('position_definitions', {}).keys()
                
                if 'Position' in df.columns or 'ì§ê¸‰' in df.columns:
                    pos_col = 'Position' if 'Position' in df.columns else 'ì§ê¸‰'
                    
                    # Positions not in matrix
                    for _, row in df.iterrows():
                        position = row.get(pos_col, '')
                        if position and position not in valid_positions:
                            self.add_error('position_errors', {
                                'id': row.get('ID No', 'N/A'),
                                'name': row.get('Name', 'N/A'),
                                'error_type': 'Unknown Position',
                                'error_column': pos_col,
                                'error_value': position,
                                'expected_value': 'Valid position from matrix',
                                'severity': 'warning',
                                'description': f'Position not in configuration: {position}',
                                'suggested_action': 'Add to position matrix or correct position'
                            })
                            
    def detect_team_errors(self, df):
        """íŒ€ ê´€ë ¨ ì˜¤ë¥˜ ê°ì§€"""
        print("  ğŸ‘¥ Detecting team errors...")
        
        # Known team name variations that should be standardized
        team_variations = {
            'OSC TEAM': 'OSC',
            'ASSEMBLEY': 'ASSEMBLY',
            'STICHING': 'STITCHING'
        }
        
        team_col = None
        for col in ['Team', 'Department', 'ë¶€ì„œ', 'TEAM']:
            if col in df.columns:
                team_col = col
                break
                
        if team_col:
            for _, row in df.iterrows():
                team = row.get(team_col, '')
                if team in team_variations:
                    self.add_error('team_errors', {
                        'id': row.get('ID No', 'N/A'),
                        'name': row.get('Name', 'N/A'),
                        'error_type': 'Inconsistent Team Name',
                        'error_column': team_col,
                        'error_value': team,
                        'expected_value': team_variations[team],
                        'severity': 'warning',
                        'description': f'Team name variation: {team}',
                        'suggested_action': f'Standardize to {team_variations[team]}'
                    })
                    
    def detect_attendance_errors(self, df):
        """ì¶œê·¼ ë°ì´í„° ì˜¤ë¥˜ ê°ì§€ - attendance CSV íŒŒì¼ ê¸°ë°˜"""
        print("  ğŸ“Š Detecting attendance errors based on actual attendance CSV data...")
        
        # attendance CSV íŒŒì¼ ì½ê¸°
        attendance_file = 'input_files/attendance/converted/attendance data august_converted.csv'
        attendance_df = None
        
        try:
            attendance_df = pd.read_csv(attendance_file, encoding='utf-8-sig')
            print(f"    âœ“ Loaded attendance data: {len(attendance_df)} records")
        except Exception as e:
            print(f"    âš ï¸ Could not read attendance file: {e}")
            # attendance íŒŒì¼ ì—†ìœ¼ë©´ ê¸°ì¡´ ë¡œì§ìœ¼ë¡œ fallback
            
        if 'Actual Working Days' in df.columns and 'Total Working Days' in df.columns:
            for _, row in df.iterrows():
                employee_id = row.get('Employee No', row.get('ID No', 'N/A'))
                total_days = row.get('Total Working Days', 0)
                actual_days = row.get('Actual Working Days', 0)
                
                # Skip if no working days data
                if pd.isna(total_days) or total_days == 0:
                    continue
                
                # attendance CSVì—ì„œ í•´ë‹¹ ì§ì› ë°ì´í„° í™•ì¸
                expected_total_days = None
                attendance_dates = []
                actual_working_count = 0
                
                if attendance_df is not None and 'ID No' in attendance_df.columns:
                    employee_attendance = attendance_df[attendance_df['ID No'] == employee_id]
                    attendance_data_count = len(employee_attendance)
                    
                    if attendance_data_count > 0:
                        # ì‹¤ì œ ë°ì´í„° ê°œìˆ˜ê°€ Total Working Daysì—¬ì•¼ í•¨
                        expected_total_days = attendance_data_count
                        
                        # ì¶œê·¼ ë‚ ì§œ ë¦¬ìŠ¤íŠ¸
                        if 'Work Date' in employee_attendance.columns:
                            employee_attendance['Work Date'] = pd.to_datetime(
                                employee_attendance['Work Date'], 
                                format='%Y.%m.%d', 
                                errors='coerce'
                            )
                            attendance_dates = employee_attendance['Work Date'].dt.strftime('%Y-%m-%d').tolist()
                        
                        # ì‹¤ì œ ì¶œê·¼(Äi lÃ m) íšŸìˆ˜
                        if 'compAdd' in employee_attendance.columns:
                            actual_working_count = (employee_attendance['compAdd'] == 'Äi lÃ m').sum()
                
                # ì˜¤ë¥˜ ì¡°ê±´ ì²´í¬
                error_conditions = []
                
                # 1. Actual > Total ì²´í¬
                if actual_days > total_days:
                    error_conditions.append(f"Actual ({actual_days}) > Total ({total_days})")
                
                # 2. Totalì´ attendance ë°ì´í„° ê°œìˆ˜ì™€ ë‹¤ë¥¸ ê²½ìš°
                if expected_total_days is not None and total_days != expected_total_days:
                    error_conditions.append(f"Total ({total_days}) â‰  Attendance data count ({expected_total_days})")
                
                # ì˜¤ë¥˜ê°€ ìˆìœ¼ë©´ ê¸°ë¡
                if error_conditions:
                    stop_date = row.get('Stop working Date', pd.NaT)
                    entrance_date = row.get('Entrance Date', pd.NaT)
                    
                    self.add_error('attendance_errors', {
                        'id': employee_id,
                        'name': row.get('Full Name', row.get('Name', 'N/A')),
                        'error_type': 'Invalid Attendance - Data Mismatch',
                        'error_column': 'Total Working Days vs Attendance Data',
                        'error_value': f"Total: {total_days}, Actual: {actual_days}, Data Count: {expected_total_days if expected_total_days else 'N/A'}",
                        'expected_value': f'Total should be {expected_total_days if expected_total_days else "based on attendance CSV"}',
                        'severity': 'critical',
                        'description': ' | '.join(error_conditions),
                        'suggested_action': f'Update Total Working Days to {expected_total_days if expected_total_days else "match attendance data"}',
                        'detailed_analysis': {
                            'entrance_date': str(entrance_date) if pd.notna(entrance_date) else None,
                            'stop_date': str(stop_date) if pd.notna(stop_date) else None,
                            'month_start': str(self.month_start),
                            'month_end': str(self.month_end),
                            'actual_working_days': actual_days,
                            'recorded_total_days': total_days,
                            'attendance_data_count': expected_total_days if expected_total_days else 0,
                            'actual_working_count': actual_working_count,
                            'sample_dates': attendance_dates[:5] if attendance_dates else []
                        }
                    })
                
            # Negative values check
            negative_actual = df[df['Actual Working Days'] < 0]
            for _, row in negative_actual.iterrows():
                self.add_error('attendance_errors', {
                    'id': row.get('Employee No', row.get('ID No', 'N/A')),
                    'name': row.get('Full Name', row.get('Name', 'N/A')),
                    'error_type': 'Negative Attendance',
                    'error_column': 'Actual Working Days',
                    'error_value': row['Actual Working Days'],
                    'expected_value': '>= 0',
                    'severity': 'critical',
                    'description': 'Negative working days recorded',
                    'suggested_action': 'Correct attendance data - negative values are invalid'
                })
                
    def detect_duplicate_errors(self, df):
        """ì¤‘ë³µ ë° ID ì˜¤ë¥˜ ê°ì§€"""
        print("  ğŸ”„ Detecting duplicate and ID errors...")
        
        if 'ID No' in df.columns:
            # Duplicate IDs
            duplicate_ids = df[df.duplicated('ID No', keep=False)]
            if not duplicate_ids.empty:
                id_groups = duplicate_ids.groupby('ID No')
                for id_no, group in id_groups:
                    names = group['Name'].unique() if 'Name' in group.columns else []
                    self.add_error('duplicate_errors', {
                        'id': id_no,
                        'name': ', '.join([str(n) for n in names]),
                        'error_type': 'Duplicate ID',
                        'error_column': 'ID No',
                        'error_value': f'{len(group)} occurrences',
                        'expected_value': 'Unique ID',
                        'severity': 'critical',
                        'description': f'ID appears {len(group)} times with names: {names}',
                        'suggested_action': 'Resolve duplicate IDs'
                    })
                    
            # Missing IDs
            missing_ids = df[df['ID No'].isna() | (df['ID No'] == '')]
            for _, row in missing_ids.iterrows():
                self.add_error('duplicate_errors', {
                    'id': 'MISSING',
                    'name': row.get('Name', 'N/A'),
                    'error_type': 'Missing ID',
                    'error_column': 'ID No',
                    'error_value': 'NULL/Empty',
                    'expected_value': 'Valid ID',
                    'severity': 'critical',
                    'description': 'Employee ID is missing',
                    'suggested_action': 'Assign employee ID'
                })
                
    def calculate_summary(self):
        """ì˜¤ë¥˜ ìš”ì•½ ê³„ì‚°"""
        total = 0
        for category in ['temporal_errors', 'type_errors', 'position_errors', 
                        'team_errors', 'attendance_errors', 'duplicate_errors']:
            total += len(self.errors[category])
        
        self.errors['summary']['total_errors'] = total
        
        print(f"\nğŸ“Š Error Detection Complete:")
        print(f"  Total Errors: {total}")
        print(f"  Critical: {self.errors['summary']['critical']}")
        print(f"  Warning: {self.errors['summary']['warning']}")
        print(f"  Info: {self.errors['summary']['info']}")
        
    def generate_error_report(self, output_path='error_report.json'):
        """ì˜¤ë¥˜ ë³´ê³ ì„œ ìƒì„±"""
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(self.errors, f, ensure_ascii=False, indent=2, default=str)
        print(f"\nğŸ“ Error report saved to: {output_path}")
        return self.errors


if __name__ == "__main__":
    # Test with August 2025 data
    import sys
    
    # Load data
    file_path = "input_files/2025ë…„ 8ì›” ì¸ì„¼í‹°ë¸Œ ì§€ê¸‰ ì„¸ë¶€ ì •ë³´.csv"
    if os.path.exists(file_path):
        df = pd.read_csv(file_path, encoding='utf-8-sig')
        
        # Parse dates
        date_columns = ['Entrance Date', 'Stop working Date']
        for col in date_columns:
            if col in df.columns:
                df[col] = pd.to_datetime(df[col], errors='coerce')
        
        # Run detection
        detector = DataErrorDetector(2025, 8)
        errors = detector.detect_all_errors(df)
        
        # Save report
        detector.generate_error_report('output_files/data_errors_2025_08.json')
        
        # Print sample errors
        print("\nğŸ“‹ Sample Errors:")
        for category, error_list in errors.items():
            if category != 'summary' and error_list:
                print(f"\n{category.upper()}:")
                for error in error_list[:2]:  # Show first 2 of each type
                    print(f"  - {error['name']} ({error['id']}): {error['description']}")
    else:
        print(f"âŒ File not found: {file_path}")