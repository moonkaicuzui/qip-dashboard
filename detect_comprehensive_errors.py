"""
Comprehensive Data Error Detection System
Îç∞Ïù¥ÌÑ∞ ÌíàÏßà Ï¢ÖÌï© Í≤ÄÏ¶ù ÏãúÏä§ÌÖú
"""

import pandas as pd
import numpy as np
import json
from datetime import datetime
import os

class DataErrorDetector:
    """Ìè¨Í¥ÑÏ†Å Îç∞Ïù¥ÌÑ∞ Ïò§Î•ò Í∞êÏßÄ ÌÅ¥ÎûòÏä§"""
    
    def __init__(self, year, month):
        self.year = year
        self.month = month
        self.month_start = pd.Timestamp(year, month, 1)
        self.month_end = pd.Timestamp(year, month, 1) + pd.DateOffset(months=1) - pd.Timedelta(days=1)
        self.errors = {
            'temporal_errors': [],
            'type_errors': [],
            'position_errors': [],
            'team_errors': [],
            'attendance_errors': [],
            'duplicate_errors': [],
            'summary': {
                'total_errors': 0,
                'critical': 0,
                'warning': 0,
                'info': 0
            }
        }
        
    def detect_all_errors(self, df):
        """Î™®Îì† Ïò§Î•ò Ïú†Ìòï Í∞êÏßÄ"""
        print("\nüîç Starting Comprehensive Error Detection...")
        
        # 1. Temporal Errors
        self.detect_temporal_errors(df)
        
        # 2. TYPE Errors
        self.detect_type_errors(df)
        
        # 3. Position Errors
        self.detect_position_errors(df)
        
        # 4. Team Errors
        self.detect_team_errors(df)
        
        # 5. Attendance Errors
        self.detect_attendance_errors(df)
        
        # 6. Duplicate Errors
        self.detect_duplicate_errors(df)
        
        # Summary
        self.calculate_summary()
        
        return self.errors
    
    def add_error(self, category, error_data):
        """Ïò§Î•ò Ï∂îÍ∞Ä Ìó¨Ìçº Ìï®Ïàò"""
        self.errors[category].append(error_data)
        
        # Update summary
        severity = error_data.get('severity', 'info')
        if severity == 'critical':
            self.errors['summary']['critical'] += 1
        elif severity == 'warning':
            self.errors['summary']['warning'] += 1
        else:
            self.errors['summary']['info'] += 1
            
    def detect_temporal_errors(self, df):
        """ÏãúÍ∞Ñ Í¥ÄÎ†® Ïò§Î•ò Í∞êÏßÄ"""
        print("  üìÖ Detecting temporal errors...")
        
        # Note: Entrance date can be after month_end because basic_manpower_data.csv 
        # is updated daily. If report is generated on Sept 15th for August,
        # employees who joined on Sept 15th will be in the data.
        # This is NOT an error - it's normal business operation.
        
        # We'll only check for clearly invalid dates (e.g., far future dates)
        # For now, we'll skip the future entrance date check entirely
        # since the business logic allows for this scenario
        
        if 'Stop working Date' in df.columns and 'Entrance Date' in df.columns:
            # Stop date before entrance date
            invalid_stop = df[
                (df['Stop working Date'].notna()) & 
                (df['Entrance Date'].notna()) &
                (df['Stop working Date'] < df['Entrance Date'])
            ]
            for _, row in invalid_stop.iterrows():
                self.add_error('temporal_errors', {
                    'id': row.get('Employee No', row.get('ID No', 'N/A')),
                    'name': row.get('Full Name', row.get('Name', 'N/A')),
                    'error_type': 'Invalid Date Sequence',
                    'error_column': 'Stop working Date',
                    'error_value': f"Stop: {row['Stop working Date']}, Enter: {row['Entrance Date']}",
                    'expected_value': 'Stop Date >= Entrance Date',
                    'severity': 'critical',
                    'description': 'Employee left before joining',
                    'suggested_action': 'Correct date sequence'
                })
                
    def detect_type_errors(self, df):
        """TYPE Î∂ÑÎ•ò Ïò§Î•ò Í∞êÏßÄ"""
        print("  üè∑Ô∏è Detecting TYPE classification errors...")
        
        type_column = 'ROLE TYPE STD' if 'ROLE TYPE STD' in df.columns else 'TYPE'
        
        if type_column in df.columns:
            # Missing TYPE
            missing_type = df[df[type_column].isna() | (df[type_column] == '')]
            for _, row in missing_type.iterrows():
                self.add_error('type_errors', {
                    'id': row.get('Employee No', row.get('ID No', 'N/A')),
                    'name': row.get('Full Name', row.get('Name', 'N/A')),
                    'error_type': 'Missing TYPE',
                    'error_column': type_column,
                    'error_value': 'NULL/Empty',
                    'expected_value': 'TYPE-1, TYPE-2, or TYPE-3',
                    'severity': 'critical',
                    'description': 'TYPE classification is missing',
                    'suggested_action': 'Assign appropriate TYPE'
                })
            
            # Invalid TYPE values
            valid_types = ['TYPE-1', 'TYPE-2', 'TYPE-3']
            invalid_type = df[
                df[type_column].notna() & 
                ~df[type_column].isin(valid_types)
            ]
            for _, row in invalid_type.iterrows():
                self.add_error('type_errors', {
                    'id': row.get('Employee No', row.get('ID No', 'N/A')),
                    'name': row.get('Full Name', row.get('Name', 'N/A')),
                    'error_type': 'Invalid TYPE',
                    'error_column': type_column,
                    'error_value': row[type_column],
                    'expected_value': 'TYPE-1, TYPE-2, or TYPE-3',
                    'severity': 'critical',
                    'description': f'Invalid TYPE value: {row[type_column]}',
                    'suggested_action': 'Correct to valid TYPE'
                })
                
    def detect_position_errors(self, df):
        """ÏßÅÍ∏â Í¥ÄÎ†® Ïò§Î•ò Í∞êÏßÄ"""
        print("  üëî Detecting position errors...")
        
        # Load position matrix if exists
        position_matrix_path = 'config_files/position_condition_matrix.json'
        if os.path.exists(position_matrix_path):
            with open(position_matrix_path, 'r', encoding='utf-8') as f:
                position_matrix = json.load(f)
                valid_positions = position_matrix.get('position_definitions', {}).keys()
                
                if 'Position' in df.columns or 'ÏßÅÍ∏â' in df.columns:
                    pos_col = 'Position' if 'Position' in df.columns else 'ÏßÅÍ∏â'
                    
                    # Positions not in matrix
                    for _, row in df.iterrows():
                        position = row.get(pos_col, '')
                        if position and position not in valid_positions:
                            self.add_error('position_errors', {
                                'id': row.get('ID No', 'N/A'),
                                'name': row.get('Name', 'N/A'),
                                'error_type': 'Unknown Position',
                                'error_column': pos_col,
                                'error_value': position,
                                'expected_value': 'Valid position from matrix',
                                'severity': 'warning',
                                'description': f'Position not in configuration: {position}',
                                'suggested_action': 'Add to position matrix or correct position'
                            })
                            
    def detect_team_errors(self, df):
        """ÌåÄ Í¥ÄÎ†® Ïò§Î•ò Í∞êÏßÄ"""
        print("  üë• Detecting team errors...")
        
        # Known team name variations that should be standardized
        team_variations = {
            'OSC TEAM': 'OSC',
            'ASSEMBLEY': 'ASSEMBLY',
            'STICHING': 'STITCHING'
        }
        
        team_col = None
        for col in ['Team', 'Department', 'Î∂ÄÏÑú', 'TEAM']:
            if col in df.columns:
                team_col = col
                break
                
        if team_col:
            for _, row in df.iterrows():
                team = row.get(team_col, '')
                if team in team_variations:
                    self.add_error('team_errors', {
                        'id': row.get('ID No', 'N/A'),
                        'name': row.get('Name', 'N/A'),
                        'error_type': 'Inconsistent Team Name',
                        'error_column': team_col,
                        'error_value': team,
                        'expected_value': team_variations[team],
                        'severity': 'warning',
                        'description': f'Team name variation: {team}',
                        'suggested_action': f'Standardize to {team_variations[team]}'
                    })
                    
    def detect_attendance_errors(self, df):
        """Ï∂úÍ∑º Îç∞Ïù¥ÌÑ∞ Ïò§Î•ò Í∞êÏßÄ - attendance CSV ÌååÏùº Í∏∞Î∞ò"""
        print("  üìä Detecting attendance errors based on actual attendance CSV data...")
        
        # attendance CSV ÌååÏùº ÏùΩÍ∏∞
        attendance_file = 'input_files/attendance/converted/attendance data august_converted.csv'
        attendance_df = None
        
        try:
            attendance_df = pd.read_csv(attendance_file, encoding='utf-8-sig')
            print(f"    ‚úì Loaded attendance data: {len(attendance_df)} records")
        except Exception as e:
            print(f"    ‚ö†Ô∏è Could not read attendance file: {e}")
            # attendance ÌååÏùº ÏóÜÏúºÎ©¥ Í∏∞Ï°¥ Î°úÏßÅÏúºÎ°ú fallback
            
        if 'Actual Working Days' in df.columns and 'Total Working Days' in df.columns:
            for _, row in df.iterrows():
                employee_id = row.get('Employee No', row.get('ID No', 'N/A'))
                total_days = row.get('Total Working Days', 0)
                actual_days = row.get('Actual Working Days', 0)
                
                # Skip if no working days data
                if pd.isna(total_days) or total_days == 0:
                    continue
                
                # attendance CSVÏóêÏÑú Ìï¥Îãπ ÏßÅÏõê Îç∞Ïù¥ÌÑ∞ ÌôïÏù∏
                expected_total_days = None
                attendance_dates = []
                actual_working_count = 0
                
                if attendance_df is not None and 'ID No' in attendance_df.columns:
                    employee_attendance = attendance_df[attendance_df['ID No'] == employee_id]
                    attendance_data_count = len(employee_attendance)
                    
                    if attendance_data_count > 0:
                        # Ïã§Ï†ú Îç∞Ïù¥ÌÑ∞ Í∞úÏàòÍ∞Ä Total Working DaysÏó¨Ïïº Ìï®
                        expected_total_days = attendance_data_count
                        
                        # Ï∂úÍ∑º ÎÇ†Ïßú Î¶¨Ïä§Ìä∏
                        if 'Work Date' in employee_attendance.columns:
                            employee_attendance['Work Date'] = pd.to_datetime(
                                employee_attendance['Work Date'], 
                                format='%Y.%m.%d', 
                                errors='coerce'
                            )
                            attendance_dates = employee_attendance['Work Date'].dt.strftime('%Y-%m-%d').tolist()
                        
                        # Ïã§Ï†ú Ï∂úÍ∑º(ƒêi l√†m) ÌöüÏàò
                        if 'compAdd' in employee_attendance.columns:
                            actual_working_count = (employee_attendance['compAdd'] == 'ƒêi l√†m').sum()
                
                # Ïò§Î•ò Ï°∞Í±¥ Ï≤¥ÌÅ¨
                error_conditions = []
                
                # 1. Actual > Total Ï≤¥ÌÅ¨
                if actual_days > total_days:
                    error_conditions.append(f"Actual ({actual_days}) > Total ({total_days})")
                
                # 2. TotalÏù¥ attendance Îç∞Ïù¥ÌÑ∞ Í∞úÏàòÏôÄ Îã§Î•∏ Í≤ΩÏö∞
                if expected_total_days is not None and total_days != expected_total_days:
                    error_conditions.append(f"Total ({total_days}) ‚â† Attendance data count ({expected_total_days})")
                
                # Ïò§Î•òÍ∞Ä ÏûàÏúºÎ©¥ Í∏∞Î°ù
                if error_conditions:
                    stop_date = row.get('Stop working Date', pd.NaT)
                    entrance_date = row.get('Entrance Date', pd.NaT)
                    
                    self.add_error('attendance_errors', {
                        'id': employee_id,
                        'name': row.get('Full Name', row.get('Name', 'N/A')),
                        'error_type': 'Invalid Attendance - Data Mismatch',
                        'error_column': 'Total Working Days vs Attendance Data',
                        'error_value': f"Total: {total_days}, Actual: {actual_days}, Data Count: {expected_total_days if expected_total_days else 'N/A'}",
                        'expected_value': f'Total should be {expected_total_days if expected_total_days else "based on attendance CSV"}',
                        'severity': 'critical',
                        'description': ' | '.join(error_conditions),
                        'suggested_action': f'Update Total Working Days to {expected_total_days if expected_total_days else "match attendance data"}',
                        'detailed_analysis': {
                            'entrance_date': str(entrance_date) if pd.notna(entrance_date) else None,
                            'stop_date': str(stop_date) if pd.notna(stop_date) else None,
                            'month_start': str(self.month_start),
                            'month_end': str(self.month_end),
                            'actual_working_days': actual_days,
                            'recorded_total_days': total_days,
                            'attendance_data_count': expected_total_days if expected_total_days else 0,
                            'actual_working_count': actual_working_count,
                            'sample_dates': attendance_dates[:5] if attendance_dates else []
                        }
                    })
                
            # Negative values check
            negative_actual = df[df['Actual Working Days'] < 0]
            for _, row in negative_actual.iterrows():
                self.add_error('attendance_errors', {
                    'id': row.get('Employee No', row.get('ID No', 'N/A')),
                    'name': row.get('Full Name', row.get('Name', 'N/A')),
                    'error_type': 'Negative Attendance',
                    'error_column': 'Actual Working Days',
                    'error_value': row['Actual Working Days'],
                    'expected_value': '>= 0',
                    'severity': 'critical',
                    'description': 'Negative working days recorded',
                    'suggested_action': 'Correct attendance data - negative values are invalid'
                })
                
    def detect_duplicate_errors(self, df):
        """Ï§ëÎ≥µ Î∞è ID Ïò§Î•ò Í∞êÏßÄ"""
        print("  üîÑ Detecting duplicate and ID errors...")
        
        if 'ID No' in df.columns:
            # Duplicate IDs
            duplicate_ids = df[df.duplicated('ID No', keep=False)]
            if not duplicate_ids.empty:
                id_groups = duplicate_ids.groupby('ID No')
                for id_no, group in id_groups:
                    names = group['Name'].unique() if 'Name' in group.columns else []
                    self.add_error('duplicate_errors', {
                        'id': id_no,
                        'name': ', '.join([str(n) for n in names]),
                        'error_type': 'Duplicate ID',
                        'error_column': 'ID No',
                        'error_value': f'{len(group)} occurrences',
                        'expected_value': 'Unique ID',
                        'severity': 'critical',
                        'description': f'ID appears {len(group)} times with names: {names}',
                        'suggested_action': 'Resolve duplicate IDs'
                    })
                    
            # Missing IDs
            missing_ids = df[df['ID No'].isna() | (df['ID No'] == '')]
            for _, row in missing_ids.iterrows():
                self.add_error('duplicate_errors', {
                    'id': 'MISSING',
                    'name': row.get('Name', 'N/A'),
                    'error_type': 'Missing ID',
                    'error_column': 'ID No',
                    'error_value': 'NULL/Empty',
                    'expected_value': 'Valid ID',
                    'severity': 'critical',
                    'description': 'Employee ID is missing',
                    'suggested_action': 'Assign employee ID'
                })
                
    def calculate_summary(self):
        """Ïò§Î•ò ÏöîÏïΩ Í≥ÑÏÇ∞"""
        total = 0
        for category in ['temporal_errors', 'type_errors', 'position_errors', 
                        'team_errors', 'attendance_errors', 'duplicate_errors']:
            total += len(self.errors[category])
        
        self.errors['summary']['total_errors'] = total
        
        print(f"\nüìä Error Detection Complete:")
        print(f"  Total Errors: {total}")
        print(f"  Critical: {self.errors['summary']['critical']}")
        print(f"  Warning: {self.errors['summary']['warning']}")
        print(f"  Info: {self.errors['summary']['info']}")
        
    def generate_error_report(self, output_path='error_report.json'):
        """Ïò§Î•ò Î≥¥Í≥†ÏÑú ÏÉùÏÑ±"""
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(self.errors, f, ensure_ascii=False, indent=2, default=str)
        print(f"\nüìÅ Error report saved to: {output_path}")
        return self.errors


if __name__ == "__main__":
    # Test with August 2025 data
    import sys
    
    # Load data
    file_path = "input_files/2025ÎÖÑ 8Ïõî Ïù∏ÏÑºÌã∞Î∏å ÏßÄÍ∏â ÏÑ∏Î∂Ä Ï†ïÎ≥¥.csv"
    if os.path.exists(file_path):
        df = pd.read_csv(file_path, encoding='utf-8-sig')
        
        # Parse dates
        date_columns = ['Entrance Date', 'Stop working Date']
        for col in date_columns:
            if col in df.columns:
                df[col] = pd.to_datetime(df[col], errors='coerce')
        
        # Run detection
        detector = DataErrorDetector(2025, 8)
        errors = detector.detect_all_errors(df)
        
        # Save report
        detector.generate_error_report('output_files/data_errors_2025_08.json')
        
        # Print sample errors
        print("\nüìã Sample Errors:")
        for category, error_list in errors.items():
            if category != 'summary' and error_list:
                print(f"\n{category.upper()}:")
                for error in error_list[:2]:  # Show first 2 of each type
                    print(f"  - {error['name']} ({error['id']}): {error['description']}")
    else:
        print(f"‚ùå File not found: {file_path}")